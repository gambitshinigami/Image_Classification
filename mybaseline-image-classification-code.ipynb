{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nnabundomr/my-image-classification-code?scriptVersionId=118684038\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"#!pip install tensorflow\n#!pip install keras\n#!pip install --upgrade tensorflow\n#!pip install tf-nightly\n#!pip uninstall tensorflow-gpu\n#!pip install tensorflow-gpu==2.8\n#!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n#!pip install pydot\n#!pip install graphviz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#Import Module for Image classification\nimport os\nimport PIL\n\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\n\nimport keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model, Sequential, load_model\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Dropout, BatchNormalization, Flatten\nfrom keras.utils import image_dataset_from_directory\nfrom keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.optimizers import Adam,Adamax\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom os.path import exists\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import kaggle\n################################################################################################################################################\n#Convert images into data-input for the model\nimage_size = (180,180)\nbatch_size = 32\ntrain_dir = '../input/chest-xray-pneumonia/chest_xray/train'\ntest_dir = '../input/chest-xray-pneumonia/chest_xray/test'\nval_dir = '../input/chest-xray-pneumonia/chest_xray/val'\n\ntrain_data = image_dataset_from_directory(\n                                        train_dir,\n                                        validation_split = 0.2,\n                                        subset = \"training\",\n                                        seed = 34,\n                                        label_mode = \"categorical\",\n                                        image_size = image_size,\n                                        batch_size =batch_size\n)\n\ntest_data = image_dataset_from_directory(\n                                        test_dir,\n                                        validation_split = 0.2,\n                                        subset = \"validation\",\n                                        seed = 34,\n                                        label_mode = \"categorical\",\n                                        image_size = image_size,\n                                        batch_size =batch_size\n)\n\nval_data = image_dataset_from_directory(\n                                        val_dir,\n                                        validation_split = 0.2,\n                                        subset = \"validation\",\n                                        seed = 34,\n                                        label_mode = \"categorical\",\n                                        image_size = image_size,\n                                        batch_size =batch_size\n)\n################################################################################################################################################\ndef build_model(old_model = None):\n    #Building the model with transfered Learning from Resnet and weight of my prior model.\n    model = Sequential()\n\n    pre_trained_model = ResNet50(\n        include_top = False,\n        input_shape = (*image_size,3),\n        pooling = \"avg\",\n        classes = len(train_data.class_names),\n        weights = \"imagenet\"\n    )\n\n    for layer in pre_trained_model.layers : \n        layer.trainable = False\n\n    model.add(pre_trained_model)\n    model.add(Flatten())\n   \n    model.add(Dense(512, activation = \"relu\"))\n    model.add(Dropout(0.25))# To reduce the effect of Overfitting\n    \n    model.add(Dense(2,activation = 'sigmoid'))\n\n    if old_model != None : #A choice to use an old model's weight or not to boost accuracy\n        #model_dir = '../input/model/' + old_model\n        #model.load_weights(model_dir)\n        pass\n    else : pass\n\n    model.compile(optimizer=Adamax(learning_rate = 0.0001),\n                    loss=\"binary_crossentropy\",\n                    metrics=['accuracy'])\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################################################################################\n#The weights of Model = rc_model.hdf5 for better accuracy.\nmy_model = build_model()\nmy_model.summary()\n\ncheckpoint_path = \"../working/checkpoints/\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\nif not exists(checkpoint_dir) : \n    os.mkdir(checkpoint_dir)\n    print(\"Create directory: \" + checkpoint_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################################################################################\n# Create a callback that saves the model's weights\nepoch = 30\ncp_callback = [\n    tf.keras.callbacks.ModelCheckpoint(checkpoint_dir + \"/Checkpoint_{epoch}.keras\"), ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model with the new callback\nhistory = my_model.fit(train_data, \n          epochs=epoch,\n          validation_data=test_data,\n          callbacks=cp_callback)  # Pass callback to training \n################################################################################################################################################","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.gcf()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.axis(\n    ymin = 0.5,\n    ymax = 1\n)\nplt.grid()\nplt.title(f'Model Accuracy for {epoch}')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(my_model, show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(val_dir+'/NORMAL/NORMAL2-IM-1431-0001.jpeg', target_size=(180,180))\nimg = keras.preprocessing.image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = preprocess_input(img)\nclasses = my_model.predict(img)\n\nscore = float(classes[0][0])\nprint(f\"This image is {100 * (1 - score):.2f}% {train_data.class_names[0]} and {100 * score:.2f}% {train_data.class_names[1]}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save model\nmodel_path = \"../working/model/\"\nmodel_dir = os.path.dirname(model_path)\n\nif not exists(model_dir) : \n    os.mkdir(model_dir)\n    print(\"Create directory: \" + model_dir)\n\nfile_count = len(os.listdir('../working/model/'))\nnew_fc=file_count + 1\n\nmy_model.save(f'../working/model/rc_model{new_fc}.hdf5')\n################################################################################################################################################","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}